{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('C:/Users/User/Desktop/work_projects/brain_signals/5/action_imagery_near_one_person_train.csv', sep=';')\n",
    "test_df = pd.read_csv('C:/Users/User/Desktop/work_projects/brain_signals/5/action_imagery_near_one_person_test.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>condition</th>\n",
       "      <th>epoch</th>\n",
       "      <th>FC5</th>\n",
       "      <th>F3</th>\n",
       "      <th>FCz</th>\n",
       "      <th>F4</th>\n",
       "      <th>FC6</th>\n",
       "      <th>C5</th>\n",
       "      <th>C3</th>\n",
       "      <th>...</th>\n",
       "      <th>CP4</th>\n",
       "      <th>CP1</th>\n",
       "      <th>CP2</th>\n",
       "      <th>FC1</th>\n",
       "      <th>FC2</th>\n",
       "      <th>FC3</th>\n",
       "      <th>FC4</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>EMG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1500</td>\n",
       "      <td>action</td>\n",
       "      <td>0</td>\n",
       "      <td>4.083370</td>\n",
       "      <td>5.773050</td>\n",
       "      <td>0.201995</td>\n",
       "      <td>2.521222</td>\n",
       "      <td>1.227479</td>\n",
       "      <td>2.879050</td>\n",
       "      <td>1.525725</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.703621</td>\n",
       "      <td>-1.617210</td>\n",
       "      <td>-1.898605</td>\n",
       "      <td>1.542511</td>\n",
       "      <td>0.800545</td>\n",
       "      <td>2.453126</td>\n",
       "      <td>2.116559</td>\n",
       "      <td>-0.374185</td>\n",
       "      <td>-0.313328</td>\n",
       "      <td>700.354006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1498</td>\n",
       "      <td>action</td>\n",
       "      <td>0</td>\n",
       "      <td>4.334879</td>\n",
       "      <td>5.940823</td>\n",
       "      <td>0.550814</td>\n",
       "      <td>3.056077</td>\n",
       "      <td>1.769989</td>\n",
       "      <td>3.052603</td>\n",
       "      <td>1.455476</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.646888</td>\n",
       "      <td>-2.230537</td>\n",
       "      <td>-2.202046</td>\n",
       "      <td>1.818585</td>\n",
       "      <td>1.163469</td>\n",
       "      <td>2.443493</td>\n",
       "      <td>2.702282</td>\n",
       "      <td>-0.555758</td>\n",
       "      <td>-0.218421</td>\n",
       "      <td>798.403551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1496</td>\n",
       "      <td>action</td>\n",
       "      <td>0</td>\n",
       "      <td>4.526513</td>\n",
       "      <td>6.035687</td>\n",
       "      <td>0.969258</td>\n",
       "      <td>3.652089</td>\n",
       "      <td>2.389096</td>\n",
       "      <td>3.180226</td>\n",
       "      <td>1.331029</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.567853</td>\n",
       "      <td>-2.934153</td>\n",
       "      <td>-2.542141</td>\n",
       "      <td>2.123369</td>\n",
       "      <td>1.610394</td>\n",
       "      <td>2.411715</td>\n",
       "      <td>3.385222</td>\n",
       "      <td>-0.746074</td>\n",
       "      <td>-0.077012</td>\n",
       "      <td>940.262532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1494</td>\n",
       "      <td>action</td>\n",
       "      <td>0</td>\n",
       "      <td>4.624738</td>\n",
       "      <td>6.031773</td>\n",
       "      <td>1.447590</td>\n",
       "      <td>4.271690</td>\n",
       "      <td>3.045508</td>\n",
       "      <td>3.238622</td>\n",
       "      <td>1.147808</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.471721</td>\n",
       "      <td>-3.688103</td>\n",
       "      <td>-2.899911</td>\n",
       "      <td>2.440374</td>\n",
       "      <td>2.123954</td>\n",
       "      <td>2.356721</td>\n",
       "      <td>4.125346</td>\n",
       "      <td>-0.930178</td>\n",
       "      <td>0.109743</td>\n",
       "      <td>1106.261350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1492</td>\n",
       "      <td>action</td>\n",
       "      <td>0</td>\n",
       "      <td>4.604022</td>\n",
       "      <td>5.912372</td>\n",
       "      <td>1.972501</td>\n",
       "      <td>4.873302</td>\n",
       "      <td>3.692196</td>\n",
       "      <td>3.210743</td>\n",
       "      <td>0.907327</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.367698</td>\n",
       "      <td>-4.444057</td>\n",
       "      <td>-3.253814</td>\n",
       "      <td>2.752333</td>\n",
       "      <td>2.678072</td>\n",
       "      <td>2.280879</td>\n",
       "      <td>4.872123</td>\n",
       "      <td>-1.092541</td>\n",
       "      <td>0.335340</td>\n",
       "      <td>1254.080696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   time condition  epoch       FC5        F3       FCz        F4       FC6  \\\n",
       "0 -1500    action      0  4.083370  5.773050  0.201995  2.521222  1.227479   \n",
       "1 -1498    action      0  4.334879  5.940823  0.550814  3.056077  1.769989   \n",
       "2 -1496    action      0  4.526513  6.035687  0.969258  3.652089  2.389096   \n",
       "3 -1494    action      0  4.624738  6.031773  1.447590  4.271690  3.045508   \n",
       "4 -1492    action      0  4.604022  5.912372  1.972501  4.873302  3.692196   \n",
       "\n",
       "         C5        C3  ...       CP4       CP1       CP2       FC1       FC2  \\\n",
       "0  2.879050  1.525725  ... -0.703621 -1.617210 -1.898605  1.542511  0.800545   \n",
       "1  3.052603  1.455476  ... -0.646888 -2.230537 -2.202046  1.818585  1.163469   \n",
       "2  3.180226  1.331029  ... -0.567853 -2.934153 -2.542141  2.123369  1.610394   \n",
       "3  3.238622  1.147808  ... -0.471721 -3.688103 -2.899911  2.440374  2.123954   \n",
       "4  3.210743  0.907327  ... -0.367698 -4.444057 -3.253814  2.752333  2.678072   \n",
       "\n",
       "        FC3       FC4        C1        C2          EMG  \n",
       "0  2.453126  2.116559 -0.374185 -0.313328   700.354006  \n",
       "1  2.443493  2.702282 -0.555758 -0.218421   798.403551  \n",
       "2  2.411715  3.385222 -0.746074 -0.077012   940.262532  \n",
       "3  2.356721  4.125346 -0.930178  0.109743  1106.261350  \n",
       "4  2.280879  4.872123 -1.092541  0.335340  1254.080696  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13464\\2411653750.py:26: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  channel_pivot['class'] = channel_pivot['class'].replace({'action': 1, 'imagery': 0})\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13464\\2411653750.py:26: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  channel_pivot['class'] = channel_pivot['class'].replace({'action': 1, 'imagery': 0})\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13464\\2411653750.py:26: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  channel_pivot['class'] = channel_pivot['class'].replace({'action': 1, 'imagery': 0})\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13464\\2411653750.py:26: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  channel_pivot['class'] = channel_pivot['class'].replace({'action': 1, 'imagery': 0})\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13464\\2411653750.py:26: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  channel_pivot['class'] = channel_pivot['class'].replace({'action': 1, 'imagery': 0})\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13464\\2411653750.py:26: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  channel_pivot['class'] = channel_pivot['class'].replace({'action': 1, 'imagery': 0})\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13464\\2411653750.py:26: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  channel_pivot['class'] = channel_pivot['class'].replace({'action': 1, 'imagery': 0})\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13464\\2411653750.py:26: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  channel_pivot['class'] = channel_pivot['class'].replace({'action': 1, 'imagery': 0})\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13464\\2411653750.py:26: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  channel_pivot['class'] = channel_pivot['class'].replace({'action': 1, 'imagery': 0})\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13464\\2411653750.py:26: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  channel_pivot['class'] = channel_pivot['class'].replace({'action': 1, 'imagery': 0})\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13464\\2411653750.py:26: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  channel_pivot['class'] = channel_pivot['class'].replace({'action': 1, 'imagery': 0})\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13464\\2411653750.py:26: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  channel_pivot['class'] = channel_pivot['class'].replace({'action': 1, 'imagery': 0})\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13464\\2411653750.py:26: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  channel_pivot['class'] = channel_pivot['class'].replace({'action': 1, 'imagery': 0})\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13464\\2411653750.py:26: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  channel_pivot['class'] = channel_pivot['class'].replace({'action': 1, 'imagery': 0})\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13464\\2411653750.py:26: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  channel_pivot['class'] = channel_pivot['class'].replace({'action': 1, 'imagery': 0})\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13464\\2411653750.py:26: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  channel_pivot['class'] = channel_pivot['class'].replace({'action': 1, 'imagery': 0})\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13464\\2411653750.py:26: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  channel_pivot['class'] = channel_pivot['class'].replace({'action': 1, 'imagery': 0})\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13464\\2411653750.py:26: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  channel_pivot['class'] = channel_pivot['class'].replace({'action': 1, 'imagery': 0})\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13464\\2411653750.py:26: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  channel_pivot['class'] = channel_pivot['class'].replace({'action': 1, 'imagery': 0})\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13464\\2411653750.py:26: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  channel_pivot['class'] = channel_pivot['class'].replace({'action': 1, 'imagery': 0})\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13464\\2411653750.py:26: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  channel_pivot['class'] = channel_pivot['class'].replace({'action': 1, 'imagery': 0})\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13464\\2411653750.py:26: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  channel_pivot['class'] = channel_pivot['class'].replace({'action': 1, 'imagery': 0})\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13464\\2411653750.py:26: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  channel_pivot['class'] = channel_pivot['class'].replace({'action': 1, 'imagery': 0})\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13464\\2411653750.py:26: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  channel_pivot['class'] = channel_pivot['class'].replace({'action': 1, 'imagery': 0})\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13464\\2411653750.py:26: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  channel_pivot['class'] = channel_pivot['class'].replace({'action': 1, 'imagery': 0})\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13464\\2411653750.py:26: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  channel_pivot['class'] = channel_pivot['class'].replace({'action': 1, 'imagery': 0})\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13464\\2411653750.py:26: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  channel_pivot['class'] = channel_pivot['class'].replace({'action': 1, 'imagery': 0})\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13464\\2411653750.py:26: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  channel_pivot['class'] = channel_pivot['class'].replace({'action': 1, 'imagery': 0})\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13464\\2411653750.py:26: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  channel_pivot['class'] = channel_pivot['class'].replace({'action': 1, 'imagery': 0})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-1500</th>\n",
       "      <th>-1498</th>\n",
       "      <th>-1496</th>\n",
       "      <th>-1494</th>\n",
       "      <th>-1492</th>\n",
       "      <th>-1490</th>\n",
       "      <th>-1488</th>\n",
       "      <th>-1486</th>\n",
       "      <th>-1484</th>\n",
       "      <th>-1482</th>\n",
       "      <th>...</th>\n",
       "      <th>1984</th>\n",
       "      <th>1986</th>\n",
       "      <th>1988</th>\n",
       "      <th>1990</th>\n",
       "      <th>1992</th>\n",
       "      <th>1994</th>\n",
       "      <th>1996</th>\n",
       "      <th>1998</th>\n",
       "      <th>2000</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.083370</td>\n",
       "      <td>4.334879</td>\n",
       "      <td>4.526513</td>\n",
       "      <td>4.624738</td>\n",
       "      <td>4.604022</td>\n",
       "      <td>4.450871</td>\n",
       "      <td>4.166431</td>\n",
       "      <td>3.767198</td>\n",
       "      <td>3.283626</td>\n",
       "      <td>2.756759</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.066176</td>\n",
       "      <td>-0.093404</td>\n",
       "      <td>-0.134609</td>\n",
       "      <td>-0.193552</td>\n",
       "      <td>-0.271726</td>\n",
       "      <td>-0.367990</td>\n",
       "      <td>-0.478605</td>\n",
       "      <td>-0.597674</td>\n",
       "      <td>-0.717894</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.710441</td>\n",
       "      <td>3.119469</td>\n",
       "      <td>3.509298</td>\n",
       "      <td>3.833146</td>\n",
       "      <td>4.046041</td>\n",
       "      <td>4.110561</td>\n",
       "      <td>4.002028</td>\n",
       "      <td>3.712450</td>\n",
       "      <td>3.252610</td>\n",
       "      <td>2.651959</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.210148</td>\n",
       "      <td>-4.961232</td>\n",
       "      <td>-5.339736</td>\n",
       "      <td>-5.378342</td>\n",
       "      <td>-5.136340</td>\n",
       "      <td>-4.691136</td>\n",
       "      <td>-4.128363</td>\n",
       "      <td>-3.531859</td>\n",
       "      <td>-2.974762</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.371299</td>\n",
       "      <td>-1.078596</td>\n",
       "      <td>-0.707978</td>\n",
       "      <td>-0.280830</td>\n",
       "      <td>0.173373</td>\n",
       "      <td>0.620318</td>\n",
       "      <td>1.024946</td>\n",
       "      <td>1.355823</td>\n",
       "      <td>1.589151</td>\n",
       "      <td>1.711820</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.658532</td>\n",
       "      <td>-0.673904</td>\n",
       "      <td>-0.728527</td>\n",
       "      <td>-0.828313</td>\n",
       "      <td>-0.975621</td>\n",
       "      <td>-1.168303</td>\n",
       "      <td>-1.399289</td>\n",
       "      <td>-1.656865</td>\n",
       "      <td>-1.925663</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.573452</td>\n",
       "      <td>-0.755460</td>\n",
       "      <td>-0.997179</td>\n",
       "      <td>-1.274642</td>\n",
       "      <td>-1.552695</td>\n",
       "      <td>-1.788347</td>\n",
       "      <td>-1.935713</td>\n",
       "      <td>-1.952022</td>\n",
       "      <td>-1.803906</td>\n",
       "      <td>-1.473097</td>\n",
       "      <td>...</td>\n",
       "      <td>6.304868</td>\n",
       "      <td>5.926523</td>\n",
       "      <td>5.259975</td>\n",
       "      <td>4.361228</td>\n",
       "      <td>3.301716</td>\n",
       "      <td>2.161404</td>\n",
       "      <td>1.021172</td>\n",
       "      <td>-0.044665</td>\n",
       "      <td>-0.974881</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.745397</td>\n",
       "      <td>1.799175</td>\n",
       "      <td>2.991199</td>\n",
       "      <td>4.242298</td>\n",
       "      <td>5.461073</td>\n",
       "      <td>6.553612</td>\n",
       "      <td>7.433904</td>\n",
       "      <td>8.033592</td>\n",
       "      <td>8.309764</td>\n",
       "      <td>8.249763</td>\n",
       "      <td>...</td>\n",
       "      <td>5.312996</td>\n",
       "      <td>4.697758</td>\n",
       "      <td>3.991115</td>\n",
       "      <td>3.241260</td>\n",
       "      <td>2.495638</td>\n",
       "      <td>1.796909</td>\n",
       "      <td>1.179665</td>\n",
       "      <td>0.668155</td>\n",
       "      <td>0.275185</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1752 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      -1500     -1498     -1496     -1494     -1492     -1490     -1488  \\\n",
       "0  4.083370  4.334879  4.526513  4.624738  4.604022  4.450871  4.166431   \n",
       "1  2.710441  3.119469  3.509298  3.833146  4.046041  4.110561  4.002028   \n",
       "2 -1.371299 -1.078596 -0.707978 -0.280830  0.173373  0.620318  1.024946   \n",
       "3 -0.573452 -0.755460 -0.997179 -1.274642 -1.552695 -1.788347 -1.935713   \n",
       "4  0.745397  1.799175  2.991199  4.242298  5.461073  6.553612  7.433904   \n",
       "\n",
       "      -1486     -1484     -1482  ...      1984      1986      1988      1990  \\\n",
       "0  3.767198  3.283626  2.756759  ... -0.066176 -0.093404 -0.134609 -0.193552   \n",
       "1  3.712450  3.252610  2.651959  ... -4.210148 -4.961232 -5.339736 -5.378342   \n",
       "2  1.355823  1.589151  1.711820  ... -0.658532 -0.673904 -0.728527 -0.828313   \n",
       "3 -1.952022 -1.803906 -1.473097  ...  6.304868  5.926523  5.259975  4.361228   \n",
       "4  8.033592  8.309764  8.249763  ...  5.312996  4.697758  3.991115  3.241260   \n",
       "\n",
       "       1992      1994      1996      1998      2000  class  \n",
       "0 -0.271726 -0.367990 -0.478605 -0.597674 -0.717894      1  \n",
       "1 -5.136340 -4.691136 -4.128363 -3.531859 -2.974762      1  \n",
       "2 -0.975621 -1.168303 -1.399289 -1.656865 -1.925663      1  \n",
       "3  3.301716  2.161404  1.021172 -0.044665 -0.974881      1  \n",
       "4  2.495638  1.796909  1.179665  0.668155  0.275185      1  \n",
       "\n",
       "[5 rows x 1752 columns]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Read the CSV file (assuming train_df is already loaded)\n",
    "\n",
    "# Step 2: Get the number of channels (i.e., the number of columns related to channels)\n",
    "# The columns start from index 3 onward for the channel columns\n",
    "channel_columns = train_df.columns[3:]\n",
    "\n",
    "# Step 3: Create a list to hold the train_dfs_raw for each channel\n",
    "train_dfs_raw = []\n",
    "\n",
    "# Iterate through each channel column\n",
    "for channel in channel_columns:\n",
    "    # Group by 'epoch' and extract the time and channel values for each epoch\n",
    "    channel_data = train_df[['time', 'epoch', 'condition', channel]]\n",
    "    \n",
    "    # Pivot the data: each epoch will become a row, and each time step will become a column\n",
    "    channel_pivot = channel_data.pivot_table(index='epoch', columns='time', values=channel, aggfunc='first')\n",
    "    \n",
    "    # Optionally, include the 'condition' (action) column in the DataFrame\n",
    "    # Use the first value of 'condition' for each epoch (this should be the same within an epoch)\n",
    "    condition_data = train_df.groupby('epoch')['condition'].first()\n",
    "    channel_pivot['class'] = condition_data  # Rename 'action' to 'class'\n",
    "    \n",
    "    # Replace 'active' with 1 and 'imagery' with 0 in the 'class' column\n",
    "    channel_pivot['class'] = channel_pivot['class'].replace({'action': 1, 'imagery': 0})\n",
    "    \n",
    "    # Drop the first column (index 0) and reset the index to avoid keeping 'epoch' as index\n",
    "    channel_pivot = channel_pivot.reset_index(drop=True)\n",
    "    \n",
    "    # Drop the row with the time ticks (which is typically the first row in the DataFrame)\n",
    "    channel_pivot.columns.name = None  # Remove the extra column header name (time ticks)\n",
    "    \n",
    "    # Append this channel's dataframe to the list\n",
    "    train_dfs_raw.append(channel_pivot)\n",
    "\n",
    "# Step 4: Verify the result for the first channel's dataframe\n",
    "train_dfs_raw[0].head()  # This will print the first few rows of the first channel's dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-1500</th>\n",
       "      <th>-1498</th>\n",
       "      <th>-1496</th>\n",
       "      <th>-1494</th>\n",
       "      <th>-1492</th>\n",
       "      <th>-1490</th>\n",
       "      <th>-1488</th>\n",
       "      <th>-1486</th>\n",
       "      <th>-1484</th>\n",
       "      <th>-1482</th>\n",
       "      <th>...</th>\n",
       "      <th>1982</th>\n",
       "      <th>1984</th>\n",
       "      <th>1986</th>\n",
       "      <th>1988</th>\n",
       "      <th>1990</th>\n",
       "      <th>1992</th>\n",
       "      <th>1994</th>\n",
       "      <th>1996</th>\n",
       "      <th>1998</th>\n",
       "      <th>2000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.907462</td>\n",
       "      <td>2.426750</td>\n",
       "      <td>1.875221</td>\n",
       "      <td>1.272268</td>\n",
       "      <td>0.639230</td>\n",
       "      <td>-0.002413</td>\n",
       "      <td>-0.632433</td>\n",
       "      <td>-1.232653</td>\n",
       "      <td>-1.787120</td>\n",
       "      <td>-2.281737</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.818938</td>\n",
       "      <td>-18.802707</td>\n",
       "      <td>-17.210196</td>\n",
       "      <td>-15.117040</td>\n",
       "      <td>-12.631809</td>\n",
       "      <td>-9.889579</td>\n",
       "      <td>-7.042112</td>\n",
       "      <td>-4.245590</td>\n",
       "      <td>-1.647241</td>\n",
       "      <td>0.627555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.802864</td>\n",
       "      <td>2.386150</td>\n",
       "      <td>1.837203</td>\n",
       "      <td>1.144311</td>\n",
       "      <td>0.302882</td>\n",
       "      <td>-0.681690</td>\n",
       "      <td>-1.791466</td>\n",
       "      <td>-2.994156</td>\n",
       "      <td>-4.242503</td>\n",
       "      <td>-5.475264</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.832444</td>\n",
       "      <td>-5.811435</td>\n",
       "      <td>-7.361442</td>\n",
       "      <td>-8.500405</td>\n",
       "      <td>-9.270933</td>\n",
       "      <td>-9.732598</td>\n",
       "      <td>-9.953737</td>\n",
       "      <td>-10.003694</td>\n",
       "      <td>-9.946272</td>\n",
       "      <td>-9.834949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.456151</td>\n",
       "      <td>-1.435524</td>\n",
       "      <td>-1.367759</td>\n",
       "      <td>-1.247154</td>\n",
       "      <td>-1.072760</td>\n",
       "      <td>-0.848981</td>\n",
       "      <td>-0.585586</td>\n",
       "      <td>-0.297083</td>\n",
       "      <td>-0.001513</td>\n",
       "      <td>0.281223</td>\n",
       "      <td>...</td>\n",
       "      <td>2.888995</td>\n",
       "      <td>2.651608</td>\n",
       "      <td>2.476217</td>\n",
       "      <td>2.373774</td>\n",
       "      <td>2.342742</td>\n",
       "      <td>2.371097</td>\n",
       "      <td>2.439533</td>\n",
       "      <td>2.525336</td>\n",
       "      <td>2.606306</td>\n",
       "      <td>2.664143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.871867</td>\n",
       "      <td>4.426501</td>\n",
       "      <td>3.920331</td>\n",
       "      <td>3.369144</td>\n",
       "      <td>2.789225</td>\n",
       "      <td>2.195908</td>\n",
       "      <td>1.602620</td>\n",
       "      <td>1.020543</td>\n",
       "      <td>0.458879</td>\n",
       "      <td>-0.074417</td>\n",
       "      <td>...</td>\n",
       "      <td>6.483555</td>\n",
       "      <td>6.479934</td>\n",
       "      <td>6.234236</td>\n",
       "      <td>5.787231</td>\n",
       "      <td>5.190877</td>\n",
       "      <td>4.503030</td>\n",
       "      <td>3.781968</td>\n",
       "      <td>3.081271</td>\n",
       "      <td>2.445578</td>\n",
       "      <td>1.907583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4.247736</td>\n",
       "      <td>-3.830939</td>\n",
       "      <td>-3.258178</td>\n",
       "      <td>-2.541434</td>\n",
       "      <td>-1.707140</td>\n",
       "      <td>-0.794214</td>\n",
       "      <td>0.149555</td>\n",
       "      <td>1.072368</td>\n",
       "      <td>1.923931</td>\n",
       "      <td>2.660936</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.695988</td>\n",
       "      <td>-5.567423</td>\n",
       "      <td>-5.299648</td>\n",
       "      <td>-4.894614</td>\n",
       "      <td>-4.366101</td>\n",
       "      <td>-3.739074</td>\n",
       "      <td>-3.047676</td>\n",
       "      <td>-2.332033</td>\n",
       "      <td>-1.634263</td>\n",
       "      <td>-0.994183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1751 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      -1500     -1498     -1496     -1494     -1492     -1490     -1488  \\\n",
       "0  2.907462  2.426750  1.875221  1.272268  0.639230 -0.002413 -0.632433   \n",
       "1  2.802864  2.386150  1.837203  1.144311  0.302882 -0.681690 -1.791466   \n",
       "2 -1.456151 -1.435524 -1.367759 -1.247154 -1.072760 -0.848981 -0.585586   \n",
       "3  4.871867  4.426501  3.920331  3.369144  2.789225  2.195908  1.602620   \n",
       "4 -4.247736 -3.830939 -3.258178 -2.541434 -1.707140 -0.794214  0.149555   \n",
       "\n",
       "      -1486     -1484     -1482  ...       1982       1984       1986  \\\n",
       "0 -1.232653 -1.787120 -2.281737  ... -19.818938 -18.802707 -17.210196   \n",
       "1 -2.994156 -4.242503 -5.475264  ...  -3.832444  -5.811435  -7.361442   \n",
       "2 -0.297083 -0.001513  0.281223  ...   2.888995   2.651608   2.476217   \n",
       "3  1.020543  0.458879 -0.074417  ...   6.483555   6.479934   6.234236   \n",
       "4  1.072368  1.923931  2.660936  ...  -5.695988  -5.567423  -5.299648   \n",
       "\n",
       "        1988       1990      1992      1994       1996      1998      2000  \n",
       "0 -15.117040 -12.631809 -9.889579 -7.042112  -4.245590 -1.647241  0.627555  \n",
       "1  -8.500405  -9.270933 -9.732598 -9.953737 -10.003694 -9.946272 -9.834949  \n",
       "2   2.373774   2.342742  2.371097  2.439533   2.525336  2.606306  2.664143  \n",
       "3   5.787231   5.190877  4.503030  3.781968   3.081271  2.445578  1.907583  \n",
       "4  -4.894614  -4.366101 -3.739074 -3.047676  -2.332033 -1.634263 -0.994183  \n",
       "\n",
       "[5 rows x 1751 columns]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Assuming test_df is your test DataFrame without the 'condition' column# Step 2: Get the number of channels (i.e., the number of columns related to channels)\n",
    "# The columns start from index 3 onward for the channel columns\n",
    "channel_columns = test_df.columns[2:]\n",
    "\n",
    "# Step 3: Create a list to hold the test_dfs_raw for each channel\n",
    "test_dfs_raw = []\n",
    "\n",
    "# Iterate through each channel column\n",
    "for channel in channel_columns:\n",
    "    # Group by 'epoch' and extract the time and channel values for each epoch\n",
    "    channel_data = test_df[['time', 'epoch', channel]]\n",
    "    \n",
    "    # Pivot the data: each epoch will become a row, and each time step will become a column\n",
    "    channel_pivot = channel_data.pivot_table(index='epoch', columns='time', values=channel, aggfunc='first')\n",
    "    \n",
    "    # If 'condition' column exists, add 'class' column (you can add your specific logic here)\n",
    "    if 'condition' in test_df.columns:\n",
    "        # Use the first value of 'condition' for each epoch (this should be the same within an epoch)\n",
    "        condition_data = test_df.groupby('epoch')['condition'].first()\n",
    "        channel_pivot['class'] = condition_data  # Rename 'action' to 'class'\n",
    "        \n",
    "        # Replace 'active' with 1 and 'imagery' with 0 in the 'class' column\n",
    "        channel_pivot['class'] = channel_pivot['class'].replace({'action': 1, 'imagery': 0})\n",
    "    \n",
    "    # Drop the first column (index 0) and reset the index to avoid keeping 'epoch' as index\n",
    "    channel_pivot = channel_pivot.reset_index(drop=True)\n",
    "    \n",
    "    # Drop the row with the time ticks (which is typically the first row in the DataFrame)\n",
    "    channel_pivot.columns.name = None  # Remove the extra column header name (time ticks)\n",
    "    \n",
    "    # Append this channel's dataframe to the list\n",
    "    test_dfs_raw.append(channel_pivot)\n",
    "\n",
    "# Step 4: Verify the result for the first channel's dataframe\n",
    "test_dfs_raw[0].head()  # This will print the first few rows of the first channel's dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-1500</th>\n",
       "      <th>-1498</th>\n",
       "      <th>-1496</th>\n",
       "      <th>-1494</th>\n",
       "      <th>-1492</th>\n",
       "      <th>-1490</th>\n",
       "      <th>-1488</th>\n",
       "      <th>-1486</th>\n",
       "      <th>-1484</th>\n",
       "      <th>-1482</th>\n",
       "      <th>...</th>\n",
       "      <th>1984</th>\n",
       "      <th>1986</th>\n",
       "      <th>1988</th>\n",
       "      <th>1990</th>\n",
       "      <th>1992</th>\n",
       "      <th>1994</th>\n",
       "      <th>1996</th>\n",
       "      <th>1998</th>\n",
       "      <th>2000</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.083370</td>\n",
       "      <td>4.334879</td>\n",
       "      <td>4.526513</td>\n",
       "      <td>4.624738</td>\n",
       "      <td>4.604022</td>\n",
       "      <td>4.450871</td>\n",
       "      <td>4.166431</td>\n",
       "      <td>3.767198</td>\n",
       "      <td>3.283626</td>\n",
       "      <td>2.756759</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.066176</td>\n",
       "      <td>-0.093404</td>\n",
       "      <td>-0.134609</td>\n",
       "      <td>-0.193552</td>\n",
       "      <td>-0.271726</td>\n",
       "      <td>-0.367990</td>\n",
       "      <td>-0.478605</td>\n",
       "      <td>-0.597674</td>\n",
       "      <td>-0.717894</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.710441</td>\n",
       "      <td>3.119469</td>\n",
       "      <td>3.509298</td>\n",
       "      <td>3.833146</td>\n",
       "      <td>4.046041</td>\n",
       "      <td>4.110561</td>\n",
       "      <td>4.002028</td>\n",
       "      <td>3.712450</td>\n",
       "      <td>3.252610</td>\n",
       "      <td>2.651959</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.210148</td>\n",
       "      <td>-4.961232</td>\n",
       "      <td>-5.339736</td>\n",
       "      <td>-5.378342</td>\n",
       "      <td>-5.136340</td>\n",
       "      <td>-4.691136</td>\n",
       "      <td>-4.128363</td>\n",
       "      <td>-3.531859</td>\n",
       "      <td>-2.974762</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.371299</td>\n",
       "      <td>-1.078596</td>\n",
       "      <td>-0.707978</td>\n",
       "      <td>-0.280830</td>\n",
       "      <td>0.173373</td>\n",
       "      <td>0.620318</td>\n",
       "      <td>1.024946</td>\n",
       "      <td>1.355823</td>\n",
       "      <td>1.589151</td>\n",
       "      <td>1.711820</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.658532</td>\n",
       "      <td>-0.673904</td>\n",
       "      <td>-0.728527</td>\n",
       "      <td>-0.828313</td>\n",
       "      <td>-0.975621</td>\n",
       "      <td>-1.168303</td>\n",
       "      <td>-1.399289</td>\n",
       "      <td>-1.656865</td>\n",
       "      <td>-1.925663</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.573452</td>\n",
       "      <td>-0.755460</td>\n",
       "      <td>-0.997179</td>\n",
       "      <td>-1.274642</td>\n",
       "      <td>-1.552695</td>\n",
       "      <td>-1.788347</td>\n",
       "      <td>-1.935713</td>\n",
       "      <td>-1.952022</td>\n",
       "      <td>-1.803906</td>\n",
       "      <td>-1.473097</td>\n",
       "      <td>...</td>\n",
       "      <td>6.304868</td>\n",
       "      <td>5.926523</td>\n",
       "      <td>5.259975</td>\n",
       "      <td>4.361228</td>\n",
       "      <td>3.301716</td>\n",
       "      <td>2.161404</td>\n",
       "      <td>1.021172</td>\n",
       "      <td>-0.044665</td>\n",
       "      <td>-0.974881</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.745397</td>\n",
       "      <td>1.799175</td>\n",
       "      <td>2.991199</td>\n",
       "      <td>4.242298</td>\n",
       "      <td>5.461073</td>\n",
       "      <td>6.553612</td>\n",
       "      <td>7.433904</td>\n",
       "      <td>8.033592</td>\n",
       "      <td>8.309764</td>\n",
       "      <td>8.249763</td>\n",
       "      <td>...</td>\n",
       "      <td>5.312996</td>\n",
       "      <td>4.697758</td>\n",
       "      <td>3.991115</td>\n",
       "      <td>3.241260</td>\n",
       "      <td>2.495638</td>\n",
       "      <td>1.796909</td>\n",
       "      <td>1.179665</td>\n",
       "      <td>0.668155</td>\n",
       "      <td>0.275185</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1752 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      -1500     -1498     -1496     -1494     -1492     -1490     -1488  \\\n",
       "0  4.083370  4.334879  4.526513  4.624738  4.604022  4.450871  4.166431   \n",
       "1  2.710441  3.119469  3.509298  3.833146  4.046041  4.110561  4.002028   \n",
       "2 -1.371299 -1.078596 -0.707978 -0.280830  0.173373  0.620318  1.024946   \n",
       "3 -0.573452 -0.755460 -0.997179 -1.274642 -1.552695 -1.788347 -1.935713   \n",
       "4  0.745397  1.799175  2.991199  4.242298  5.461073  6.553612  7.433904   \n",
       "\n",
       "      -1486     -1484     -1482  ...      1984      1986      1988      1990  \\\n",
       "0  3.767198  3.283626  2.756759  ... -0.066176 -0.093404 -0.134609 -0.193552   \n",
       "1  3.712450  3.252610  2.651959  ... -4.210148 -4.961232 -5.339736 -5.378342   \n",
       "2  1.355823  1.589151  1.711820  ... -0.658532 -0.673904 -0.728527 -0.828313   \n",
       "3 -1.952022 -1.803906 -1.473097  ...  6.304868  5.926523  5.259975  4.361228   \n",
       "4  8.033592  8.309764  8.249763  ...  5.312996  4.697758  3.991115  3.241260   \n",
       "\n",
       "       1992      1994      1996      1998      2000  class  \n",
       "0 -0.271726 -0.367990 -0.478605 -0.597674 -0.717894      1  \n",
       "1 -5.136340 -4.691136 -4.128363 -3.531859 -2.974762      1  \n",
       "2 -0.975621 -1.168303 -1.399289 -1.656865 -1.925663      1  \n",
       "3  3.301716  2.161404  1.021172 -0.044665 -0.974881      1  \n",
       "4  2.495638  1.796909  1.179665  0.668155  0.275185      1  \n",
       "\n",
       "[5 rows x 1752 columns]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dfs_raw[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1751"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_dfs_raw[0].shape[1]\n",
    "test_dfs_raw[0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dfs_raw_cut = []\n",
    "\n",
    "for df in train_dfs_raw:\n",
    "    df = df.iloc[:, 500:-500]\n",
    "    train_dfs_raw_cut.append(df)\n",
    "\n",
    "train_df_raw_cut_0 = train_dfs_raw_cut[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dfs_raw_cut = []\n",
    "\n",
    "for df in test_dfs_raw:\n",
    "    df = df.iloc[:, 500:-499]\n",
    "    test_dfs_raw_cut.append(df)\n",
    "\n",
    "test_df_raw_cut_0 = test_dfs_raw_cut[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "752"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_dfs_raw_cut[0].head()\n",
    "train_dfs_raw_cut[0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 25\n",
    "\n",
    "def smoothing_row(df, window_size):\n",
    "    smoothed_df = df.apply(lambda row: row.rolling(window=window_size, min_periods=1).mean(), axis=1)\n",
    "    return smoothed_df\n",
    "\n",
    "train_dfs_raw_cut_smooth = [smoothing_row(df, window_size) for df in train_dfs_raw_cut]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 25\n",
    "\n",
    "def smoothing_row(df, window_size):\n",
    "    smoothed_df = df.apply(lambda row: row.rolling(window=window_size, min_periods=1).mean(), axis=1)\n",
    "    return smoothed_df\n",
    "\n",
    "test_dfs_raw_cut_smooth = [smoothing_row(df, window_size) for df in test_dfs_raw_cut]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Нейросеть "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each dataframe to a NumPy array and stack them\n",
    "data_arrays = [df.values for df in train_dfs_raw_cut_smooth]  # List of arrays with shape [500, 150]\n",
    "data = np.stack(data_arrays, axis=1)  # Shape: [500, 6, 150]\n",
    "\n",
    "# Convert labels to NumPy array (ensure it's binary: 0 or 1)\n",
    "labels = train_dfs_raw[0].iloc[:, -1].values  # Shape: [500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SignalDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data (numpy.ndarray): Array of shape [num_samples, channels, time_steps]\n",
    "            labels (numpy.ndarray): Array of shape [num_samples]\n",
    "        \"\"\"\n",
    "        self.data = torch.tensor(data, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "# Create Dataset instances\n",
    "train_dataset = SignalDataset(X_train, y_train)\n",
    "test_dataset = SignalDataset(X_test, y_test)\n",
    "\n",
    "# Now, let's balance the test dataset\n",
    "# Get indices for each class\n",
    "class_0_indices = np.where(y_test == 0)[0]\n",
    "class_1_indices = np.where(y_test == 1)[0]\n",
    "\n",
    "# We will take the minimum length of both classes to ensure balance\n",
    "min_class_size = min(len(class_0_indices), len(class_1_indices))\n",
    "\n",
    "# Select a random subset of indices from each class to balance the test dataset\n",
    "class_0_sampled = np.random.choice(class_0_indices, min_class_size, replace=False)\n",
    "class_1_sampled = np.random.choice(class_1_indices, min_class_size, replace=False)\n",
    "\n",
    "# Combine the indices\n",
    "balanced_indices = np.concatenate([class_0_sampled, class_1_sampled])\n",
    "\n",
    "# Create a balanced test dataset\n",
    "balanced_test_dataset = Subset(test_dataset, balanced_indices)\n",
    "\n",
    "# Create DataLoader for the balanced test set\n",
    "batch_size = 32\n",
    "test_loader = DataLoader(balanced_test_dataset, batch_size=batch_size, shuffle=False)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_LSTM_Model(nn.Module):\n",
    "    def __init__(self, num_channels=29, time_steps=752, cnn_out_channels=128, \n",
    "                 cnn_kernel_size=3, lstm_hidden_size=128, lstm_num_layers=2, \n",
    "                 num_classes=2, dropout=0.5):\n",
    "        super(CNN_LSTM_Model, self).__init__()\n",
    "        \n",
    "        # CNN component\n",
    "        self.conv1 = nn.Conv1d(in_channels=num_channels, out_channels=cnn_out_channels, kernel_size=cnn_kernel_size, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(cnn_out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
    "        \n",
    "        # Calculate the new time_steps after Conv and Pooling\n",
    "        self.conv_output_time_steps = time_steps // 2  # After MaxPool with kernel_size=2\n",
    "        \n",
    "        # LSTM component\n",
    "        self.lstm = nn.LSTM(input_size=cnn_out_channels, \n",
    "                            hidden_size=lstm_hidden_size, \n",
    "                            num_layers=lstm_num_layers, \n",
    "                            batch_first=True, \n",
    "                            dropout=dropout)\n",
    "        \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(lstm_hidden_size, num_classes)\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor of shape [batch_size, channels, time_steps]\n",
    "        Returns:\n",
    "            out: Tensor of shape [batch_size, num_classes]\n",
    "        \"\"\"\n",
    "        # CNN layers\n",
    "        x = self.conv1(x)  # [batch, cnn_out_channels, time_steps]\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)  # [batch, cnn_out_channels, time_steps/2]\n",
    "        \n",
    "        # Prepare for LSTM: transpose to [batch, time_steps, features]\n",
    "        x = x.permute(0, 2, 1)  # [batch, time_steps/2, cnn_out_channels]\n",
    "        \n",
    "        # LSTM layers\n",
    "        lstm_out, (hn, cn) = self.lstm(x)  # lstm_out: [batch, time_steps/2, lstm_hidden_size]\n",
    "        \n",
    "        # Take the last time step's output\n",
    "        out = lstm_out[:, -1, :]  # [batch, lstm_hidden_size]\n",
    "        \n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out)  # [batch, num_classes]\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Assuming `labels` is already defined (e.g., the target labels for training)\n",
    "# Convert labels to a numpy array if they are not already\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Calculate class weights (use sklearn.utils.class_weight)\n",
    "class_weights = compute_class_weight('balanced', classes=np.array([0, 1]), y=labels)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "\n",
    "# Instantiate the model\n",
    "model = CNN_LSTM_Model()\n",
    "model.to(device)\n",
    "\n",
    "# Use weighted loss function\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# Define optimizer (Adam optimizer with a learning rate of 1e-3)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 9/9 [00:17<00:00,  1.93s/batch, loss=0.616]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.6161, Train AUC: 0.7393\n",
      "Epoch [1/10], Test AUC: 0.8714\n",
      "Best model saved with AUC: 0.8714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 9/9 [00:16<00:00,  1.88s/batch, loss=0.497]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Loss: 0.4969, Train AUC: 0.8633\n",
      "Epoch [2/10], Test AUC: 0.8907\n",
      "Best model saved with AUC: 0.8907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 9/9 [00:17<00:00,  1.99s/batch, loss=0.492]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Loss: 0.4923, Train AUC: 0.8345\n",
      "Epoch [3/10], Test AUC: 0.8944\n",
      "Best model saved with AUC: 0.8944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 9/9 [00:08<00:00,  1.01batch/s, loss=0.499]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Loss: 0.4989, Train AUC: 0.8809\n",
      "Epoch [4/10], Test AUC: 0.9008\n",
      "Best model saved with AUC: 0.9008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 9/9 [00:16<00:00,  1.87s/batch, loss=0.394]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Loss: 0.3940, Train AUC: 0.9029\n",
      "Epoch [5/10], Test AUC: 0.9183\n",
      "Best model saved with AUC: 0.9183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 9/9 [00:17<00:00,  1.97s/batch, loss=0.395]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Loss: 0.3949, Train AUC: 0.8831\n",
      "Epoch [6/10], Test AUC: 0.9284\n",
      "Best model saved with AUC: 0.9284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 9/9 [00:12<00:00,  1.43s/batch, loss=0.401]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Loss: 0.4014, Train AUC: 0.9014\n",
      "Epoch [7/10], Test AUC: 0.9642\n",
      "Best model saved with AUC: 0.9642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 9/9 [00:12<00:00,  1.35s/batch, loss=0.374]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Loss: 0.3737, Train AUC: 0.9248\n",
      "Epoch [8/10], Test AUC: 0.9449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 9/9 [00:12<00:00,  1.38s/batch, loss=0.327]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Loss: 0.3265, Train AUC: 0.9201\n",
      "Epoch [9/10], Test AUC: 0.9486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 9/9 [00:09<00:00,  1.02s/batch, loss=0.378]\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13464\\3264713664.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Loss: 0.3780, Train AUC: 0.9179\n",
      "Epoch [10/10], Test AUC: 0.9486\n",
      "Final Test AUC: 0.9642\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "num_epochs = 10  # Adjust based on convergence\n",
    "best_auc = 0.0\n",
    "best_model_path = 'best_cnn_lstm_model_auc.pth'\n",
    "\n",
    "# Outer loop with tqdm for epoch tracking\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    all_preds_prob_train = []  # Store predicted probabilities on training data\n",
    "    all_targets_train = []  # Store true labels on training data\n",
    "    \n",
    "    # Use tqdm for batch-level progress\n",
    "    with tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch') as batch_progress:\n",
    "        for batch_idx, (signals, targets) in enumerate(batch_progress):\n",
    "            signals = signals.to(device)  # [batch, 6, 150]\n",
    "            targets = targets.to(device)  # [batch]\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(signals)  # [batch, 2]\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # Store predicted probabilities (softmax outputs) for AUC calculation\n",
    "            prob = torch.softmax(outputs, dim=1)  # [batch, 2]\n",
    "            all_preds_prob_train.extend(prob.cpu().detach().numpy())  # Store in CPU for AUC calculation\n",
    "            all_targets_train.extend(targets.cpu().numpy())  # Store true labels in CPU\n",
    "            \n",
    "            # Update tqdm with current loss for each batch\n",
    "            batch_progress.set_postfix(loss=running_loss / (batch_idx + 1))\n",
    "    \n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "\n",
    "    # Calculate AUC on the training data (to track training progress)\n",
    "    auc_train = roc_auc_score(all_targets_train, np.array(all_preds_prob_train)[:, 1])  # AUC for the positive class (class 1)\n",
    "    \n",
    "    # Print AUC and loss for the epoch\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, Train AUC: {auc_train:.4f}')\n",
    "    \n",
    "    # Evaluate on the test set for AUC after every epoch\n",
    "    model.eval()\n",
    "    all_preds_prob_test = []  # Store predicted probabilities on test data\n",
    "    all_targets_test = []  # Store true labels on test data\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for signals, targets in test_loader:\n",
    "            signals = signals.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            outputs = model(signals)\n",
    "            prob = torch.softmax(outputs, dim=1)  # [batch, 2]\n",
    "            \n",
    "            all_preds_prob_test.extend(prob.cpu().numpy())\n",
    "            all_targets_test.extend(targets.cpu().numpy())\n",
    "    \n",
    "    # Calculate AUC on the test data\n",
    "    auc_test = roc_auc_score(all_targets_test, np.array(all_preds_prob_test)[:, 1])\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Test AUC: {auc_test:.4f}')\n",
    "    \n",
    "    # Save the model with the best AUC on the test set\n",
    "    if auc_test > best_auc:\n",
    "        best_auc = auc_test\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f'Best model saved with AUC: {best_auc:.4f}')\n",
    "\n",
    "# After training, load the best model and evaluate it on the test data\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model.eval()\n",
    "\n",
    "# Final evaluation on the test set (for the record)\n",
    "all_preds_prob_test_final = []\n",
    "all_targets_test_final = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for signals, targets in test_loader:\n",
    "        signals = signals.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        outputs = model(signals)\n",
    "        prob = torch.softmax(outputs, dim=1)  # [batch, 2]\n",
    "        \n",
    "        all_preds_prob_test_final.extend(prob.cpu().numpy())\n",
    "        all_targets_test_final.extend(targets.cpu().numpy())\n",
    "\n",
    "# Calculate final AUC on the test data\n",
    "final_auc_test = roc_auc_score(all_targets_test_final, np.array(all_preds_prob_test_final)[:, 1])\n",
    "print(f'Final Test AUC: {final_auc_test:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_13464\\1752453437.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('best_cnn_lstm_model_auc.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Accuracy: 0.7424\n",
      "Final Confusion Matrix (readable format):\n",
      "True Negative (TN): 32\n",
      "False Positive (FP): 1\n",
      "False Negative (FN): 16\n",
      "True Positive (TP): 17\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.97      0.79        33\n",
      "           1       0.94      0.52      0.67        33\n",
      "\n",
      "    accuracy                           0.74        66\n",
      "   macro avg       0.81      0.74      0.73        66\n",
      "weighted avg       0.81      0.74      0.73        66\n",
      "\n",
      "\n",
      "Confusion Matrix (standard format):\n",
      "[[32  1]\n",
      " [16 17]]\n",
      "\n",
      "Comparison of True and Predicted Labels (first 10 rows):\n",
      "   True Label  Predicted Label\n",
      "0           0                0\n",
      "1           0                0\n",
      "2           0                0\n",
      "3           0                0\n",
      "4           0                0\n",
      "5           0                0\n",
      "6           0                0\n",
      "7           0                0\n",
      "8           0                0\n",
      "9           0                0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "# Load the best model\n",
    "model.load_state_dict(torch.load('best_cnn_lstm_model_auc.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Final evaluation on the test set\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for signals, targets in test_loader:\n",
    "        signals = signals.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        outputs = model(signals)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "# Calculate final accuracy\n",
    "final_accuracy = accuracy_score(all_targets, all_preds)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "final_cm = confusion_matrix(all_targets, all_preds)\n",
    "\n",
    "# Extract TP, TN, FP, FN\n",
    "TN, FP, FN, TP = final_cm.ravel()\n",
    "\n",
    "# Print the accuracy and confusion matrix in a readable way\n",
    "print(f'Final Test Accuracy: {final_accuracy:.4f}')\n",
    "print(f'Final Confusion Matrix (readable format):')\n",
    "print(f'True Negative (TN): {TN}')\n",
    "print(f'False Positive (FP): {FP}')\n",
    "print(f'False Negative (FN): {FN}')\n",
    "print(f'True Positive (TP): {TP}')\n",
    "\n",
    "# Classification Report (precision, recall, F1-score)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(all_targets, all_preds))\n",
    "\n",
    "# Optionally, you can print the confusion matrix in the usual format as well\n",
    "print(f'\\nConfusion Matrix (standard format):\\n{final_cm}')\n",
    "\n",
    "# Create the Comparison Table: True Labels vs Predicted Labels\n",
    "comparison_df = pd.DataFrame({\n",
    "    'True Label': all_targets,\n",
    "    'Predicted Label': all_preds\n",
    "})\n",
    "\n",
    "print(\"\\nComparison of True and Predicted Labels (first 10 rows):\")\n",
    "print(comparison_df.head(10))  # Display the first 10 rows for inspection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предсказание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted classes for the test set: [1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Convert each dataframe in test_dfs_raw_smooth to a NumPy array and stack them\n",
    "test_data_arrays = [df.values for df in test_dfs_raw_cut_smooth]  # List of arrays with shape [N, 150]\n",
    "test_data = np.stack(test_data_arrays, axis=1)  # Shape: [N, 6, 150]\n",
    "\n",
    "# Create a Dataset instance for test-only (without labels)\n",
    "class TestOnlyDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data (numpy.ndarray): Array of shape [num_samples, channels, time_steps]\n",
    "        \"\"\"\n",
    "        self.data = torch.tensor(data, dtype=torch.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "# Create a DataLoader for `test_dfs_raw_smooth` (features only)\n",
    "test_only_dataset = TestOnlyDataset(test_data)\n",
    "batch_size = 32\n",
    "test_only_loader = DataLoader(test_only_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Use the trained model to make predictions on the test data (features only)\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "all_preds = []\n",
    "\n",
    "# Iterate over the test-only loader and make predictions\n",
    "with torch.no_grad():\n",
    "    for signals in test_only_loader:\n",
    "        signals = signals.to(device)  # Move to GPU if needed\n",
    "        \n",
    "        outputs = model(signals)  # Get model output\n",
    "        _, preds = torch.max(outputs, 1)  # Get predicted class (0 or 1)\n",
    "        \n",
    "        all_preds.extend(preds.cpu().numpy())  # Store predictions on CPU\n",
    "\n",
    "# all_preds now contains all the predicted class labels (0 or 1)\n",
    "print(f'Predicted classes for the test set: {all_preds}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'C:/Users/User/Desktop/work_projects/brain_signals/5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to: C:/Users/User/Desktop/work_projects/brain_signals/5\\predictions.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Ensure the folder exists, create it if necessary\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "\n",
    "# Convert predictions to binary string\n",
    "binary_string = ''.join([str(pred) for pred in all_preds])\n",
    "\n",
    "# Define the full file path\n",
    "file_path = os.path.join(folder_path, 'predictions.csv')\n",
    "\n",
    "# Write the binary string to the CSV file without any headers or index\n",
    "with open(file_path, 'w') as f:\n",
    "    f.write(binary_string)\n",
    "\n",
    "print(f\"File saved to: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = pd.read_csv('C:/Users/User/Desktop/work_projects/brain_signals/5/predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100000101010001101000011000000100000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [100000101010001101000011000000100000]\n",
       "Index: []"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(answer.iloc[0:0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9c49156552fdbe3eac4bc6642c7ff5495a4b0da6602444b2dc2d686dc69f26c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
